# -*- coding: utf-8 -*-
"""Code_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1smJKKFMQ67PlMVZmZlBGBMCz8gIAKyaP

# Task- 1.1

### Task- 1.1.1 : Identifying the Ideal Functions Based on Training Data
"""

import pandas as pd
import numpy as np
from google.colab import drive
from google.colab import files

drive.mount('/content/drive')

PerfectFitData = pd.read_csv("/content/drive/MyDrive/Dataset/lokesh/ideal.csv")
EvaluationDataPoints = pd.read_csv("/content/drive/MyDrive/Dataset/lokesh/test.csv")

trainInputData = pd.read_csv("/content/drive/MyDrive/Dataset/lokesh/train.csv")

class PerfectFitSelector:
    def __init__(self, trainInputData, PerfectFitData):
        self.trainInputData = trainInputData
        self.PerfectFitData = PerfectFitData

    def pick_best_fit_functions(self):
        """
        Identify the top four functions that achieve the lowest sum of squared errors.
        """
        chosen_functions = []
        highest_deviations = []

        for train_column, train_values in self.trainInputData.iloc[:, 1:].items():
            optimal_function = None
            lowest_sse = float('inf')
            max_abs_D = 0

            for ideal_column, ideal_values in self.PerfectFitData.iloc[:, 1:].items():
                sse = np.sum((train_values - ideal_values) ** 2)

                if sse < lowest_sse:
                    lowest_sse = sse
                    optimal_function = ideal_column
                    max_abs_D = np.max(np.abs(train_values - ideal_values))

            chosen_functions.append(optimal_function)
            highest_deviations.append(max_abs_D)

        return chosen_functions, highest_deviations

function_picker = PerfectFitSelector(trainInputData, PerfectFitData)
optimal_functions, greatest_deviation = function_picker.pick_best_fit_functions()

best_fit_functions = [
    PerfectFitData.loc[:, ['x', function_label]].rename(columns={function_label: 'y'})
    for function_label in optimal_functions
]
print("Selected Ideal Functions:", optimal_functions)
print("Maximum Deviations:", greatest_deviation)

"""# Task-1.1.2 : Mapping Test points to Ideal/optimal  Functions"""

class PerfectFitFunctionMapper:
    def __init__(self, optimal_functions, greatest_deviation):
        self.optimal_functions = optimal_functions
        self.greatest_deviation = greatest_deviation

    def map_EvaluationDataPoints(self, EvaluationDataPoints):
        """
        Assign each test data point to the nearest ideal function, provided it meets the deviation threshold.
        """
        mapResFunct = []
        sqrt_two = np.sqrt(2)

        for _, data_point in EvaluationDataPoints.iterrows():
            x_value, y_value = data_point['x'], data_point['y']
            closest_function = None
            lowest_deviation = float('inf')

            for i, reference_function in enumerate(self.optimal_functions):
                if x_value in reference_function['x'].values:
                    expected_y_value = reference_function.loc[reference_function['x'] == x_value, 'y'].values[0]
                    error_margin = abs(y_value - expected_y_value)

                    if error_margin <= self.greatest_deviation[i] * sqrt_two and error_margin < lowest_deviation:
                        closest_function = f"ideal_function_{i + 1}"
                        lowest_deviation = error_margin

            mapResFunct.append({
                'x': x_value,
                'y': y_value,
                'mapped_function': closest_function,
                'deviation': lowest_deviation if closest_function else None
            })

            df = pd.DataFrame(mapResFunct)

        return df

mapResFunct = PerfectFitFunctionMapper(best_fit_functions, greatest_deviation)
EvalmapPoint = mapResFunct.map_EvaluationDataPoints(EvaluationDataPoints)
best_fit_functions

EvalmapPoint.head(12)

"""### Task- 1.1.3 : Data Visualization"""

from bokeh.plotting import figure, show, output_file
from bokeh.models import ColumnDataSource
from bokeh.layouts import gridplot

class BokehVisualizer:
    def __init__(self, trainInputData, EvaluationDataPoints, best_fit_functions, EvalmapPoint):
        """
        Set up the visualizer with the required datasets.

        :param trainInputData: DataFrame containing the training dataset.
        :param EvaluationDataPoints: DataFrame with test data points.
        :param best_fit_functions: List of DataFrames representing the closest matching ideal functions.
        :param EvalmapPoint: DataFrame storing test points along with their assigned ideal functions and deviation values.
        """
        self.trainInputData = trainInputData
        self.EvaluationDataPoints = EvaluationDataPoints
        self.best_fit_functions = best_fit_functions
        self.EvalmapPoint = EvalmapPoint

    def plot_training_vs_reference(self):
        """
        Plot training data alongside its corresponding reference (ideal) functions using Bokeh.
        """
        plots = []

        for i in range(1, len(self.trainInputData.columns)):  # Start from index 1 to skip 'x' column
            column = self.trainInputData.iloc[:, i].name  # Get the column name

            visualplot = figure(title=f"Training Input Data vs Reference Function {i}",
                     width=700, height=400)

            # Plot training data points
            visualplot.scatter(self.trainInputData['x'], self.trainInputData.iloc[:, i],
                    size=8, color="blue", legend_label=f"Training Data y{i}")

            # Plot best matching reference function
            reference_func = self.best_fit_functions[i - 1]
            visualplot.line(reference_func['x'], reference_func['y'],
                line_width=2, color="red", legend_label=f"Reference Function {i}")

            visualplot.legend.location = "top_left"
            visualplot.legend.title = "Legend"
            plots.append(visualplot)

        # Arrange plots in a grid layout
        grid = gridplot([plots[:2], plots[2:]])

        output_file("/content/training_vs_reference.html")
        #files.download('/content/drive/MyDrive/Dataset/lokesh/training_vs_reference.html')
        show(grid)

    def plot_evaluationpoints_mappings(self):
          """
          Visualize test data points and their assigned reference functions.
          """
          plotvisual = figure(title="Test Data Mappings to Reference Functions",
                              width=700, height=400)  # Corrected attributes

          shadesFunct = ["red", "green", "blue", "purple"]

          # Plot ideal functions
          for i in range(len(self.best_fit_functions)):  # Using range() instead of enumerate()
              reference_func = self.best_fit_functions[i]
              plotvisual.line(reference_func['x'], reference_func['y'],
                              line_width=2, color=shadesFunct[i], legend_label=f"Reference Function {i + 1}")

          # Plot mapped test data points
          MappedTestPointData = ColumnDataSource(self.EvalmapPoint)
          plotvisual.scatter(x="x", y="y", size=10, color="orange", source=MappedTestPointData, legend_label="Test Data Points")

          # Setting legend title
          plotvisual.legend.title = "Legend"

          # Output and display the plot

          output_file("/content/test_data_mappings.html")
          #files.download("/content/drive/MyDrive/Dataset/lokesh/test_data_mappings.html")
          show(plotvisual)

from bokeh.plotting import figure, output_file, show
from bokeh.models import ColumnDataSource

visualizer = BokehVisualizer(trainInputData, EvaluationDataPoints, best_fit_functions, EvalmapPoint)

visualizer.plot_training_vs_reference()

visualizer.plot_evaluationpoints_mappings()

"""### Task- 1.1.4 : Unit Test"""

import unittest
from io import StringIO

train_csv = """x,y1,y2,y3,y4
-20,39.778572,-40.07859,-20.214268,-0.32491425
-19.9,39.604813,-39.784,-20.07095,-0.058819864
-19.8,40.09907,-40.018845,-19.906782,-0.4518296
"""
test_csv = """x,y
17.5,34.16104
0.3,1.2151024
-8.7,-16.843908
"""
ideal_csv = """x,y1,y2,y3,y4
-20,-0.9129453,0.40808207,9.087055,5.408082
-19.9,-0.8676441,0.4971858,9.132356,5.4971857
-19.8,-0.8390715,0.81616414,9.094273,5.589018
"""

trainInputData = pd.read_csv(StringIO(train_csv))
EvaluationDataPoints = pd.read_csv(StringIO(test_csv))
PerfectFitData = pd.read_csv(StringIO(ideal_csv))

class TestPerfectFitSelector(unittest.TestCase):
    def test_pick_best_fit_functions(self):
        from __main__ import PerfectFitSelector
        selector = PerfectFitSelector(trainInputData, PerfectFitData)
        selected_functions, greatest_deviation = selector.pick_best_fit_functions()

        self.assertEqual(len(selected_functions), 4)

        self.assertIsInstance(selected_functions, list)
        self.assertIsInstance(greatest_deviation, list)

        self.assertTrue(all(dev >= 0 for dev in greatest_deviation))

class TestPerfectFitFunctionMapper(unittest.TestCase):
    def test_map_EvaluationDataPoints(self):
        from __main__ import PerfectFitFunctionMapper

        selected_optimal_functions = [
            PerfectFitData[['x', 'y1']].rename(columns={'y1': 'y'}),
            PerfectFitData[['x', 'y2']].rename(columns={'y2': 'y'}),
            PerfectFitData[['x', 'y3']].rename(columns={'y3': 'y'}),
            PerfectFitData[['x', 'y4']].rename(columns={'y4': 'y'}),
        ]
        greatest_deviation = [1.0, 1.2, 2.0, 0.8]

        mapper = PerfectFitFunctionMapper(selected_optimal_functions, greatest_deviation)
        mapped_results = mapper.map_EvaluationDataPoints(EvaluationDataPoints)

        self.assertEqual(len(mapped_results), len(EvaluationDataPoints))

        valid_functions = {f"ideal_function_{i+1}" for i in range(len(selected_optimal_functions))}
        self.assertTrue(all(
            row['mapped_function'] in valid_functions or pd.isna(row['mapped_function'])
            for _, row in mapped_results.iterrows()
        ))

class TestBokehVisualizer(unittest.TestCase):
    def test_visualization(self):
        from __main__ import BokehVisualizer

        # Prepare the chosen ideal functions in a structured way
        chosen_ideal_functions = [
            PerfectFitData[['x', f'y{i}']].rename(columns={f'y{i}': 'y'}) for i in range(1, 5)
        ]

        # Prepare the DataFrame for mapped test results
        mapped_test_results = pd.DataFrame({
            'x': EvaluationDataPoints['x'],
            'y': EvaluationDataPoints['y'],
            'mapped_function': ['ideal_function_1', None, 'ideal_function_3'],
            'deviation': [0.1, None, 1.5],
        })

        # Initialize the visualizer with pre-defined variables
        visualizer = BokehVisualizer(
            trainInputData,
            EvaluationDataPoints,
            chosen_ideal_functions,
            mapped_test_results
        )

        self.assertIsNotNone(visualizer)

unittest.main(argv=[''], verbosity=2, exit=False)

"""# Task- 1.2"""

import matplotlib.pyplot as plt
from sqlalchemy import create_engine, Column, Integer, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import IntegrityError

# Define the base class for SQLAlchemy models
Base = declarative_base()

# Table to store training dataset
class TrainingDataset(Base):
    __tablename__ = 'train_functions'
    id = Column(Integer, primary_key=True, autoincrement=True)
    x_value = Column(Float)
    y_value_1 = Column(Float)
    y_value_2 = Column(Float)
    y_value_3 = Column(Float)
    y_value_4 = Column(Float)

# Table to store ideal function mappings
class ReferenceFunctions(Base):
    __tablename__ = 'reference_functions'
    id = Column(Integer, primary_key=True, autoincrement=True)
    x_value = Column(Float)
    reference_y1 = Column(Float)
    reference_y2 = Column(Float)

# Table to store test evaluation results
class EvaluationResults(Base):
    __tablename__ = 'evaluation_results'
    id = Column(Integer, primary_key=True, autoincrement=True)
    x_value = Column(Float)
    test_y_value = Column(Float)
    delta_y_deviation = Column(Float)
    matched_function_id = Column(Integer)

# Set up SQLite database connection
database_engine = create_engine('sqlite:///Functional_Test1.db', echo=True)

# Create all tables defined above
Base.metadata.create_all(database_engine)

# Create a session to interact with the database
DatabaseSession = sessionmaker(bind=database_engine)
dbConn = DatabaseSession()

class DatasetHandler:
    def __init__(self, dbConn):
        """Initialize the dataset handler with a database session."""
        self.dbConn = dbConn

    def load_dataset(self, file_path, dataset_type):
        """Generic method to import various datasets."""
        df = pd.read_csv(file_path)
        for _, entry in df.iterrows():
            if dataset_type == 'training':
                self.store_training_data(entry)
            elif dataset_type == 'reference':
                self.store_reference_functions(entry)
            elif dataset_type == 'evaluation':
                self.store_evaluation_results(entry)
        self.dbConn.commit()

    def store_training_data(self, entry):
        """Save training dataset records."""
        try:
            self.dbConn.add(TrainingDataset(
                x_value=entry['x'],
                y_value_1=entry['y1'],
                y_value_2=entry['y2'],
                y_value_3=entry['y3'],
                y_value_4=entry['y4']
            ))
        except IntegrityError as e:
            print(f"Error inserting training dataset entry: {e}")

    def store_reference_functions(self, entry):
        """Save reference function data."""
        try:
            self.dbConn.add(ReferenceFunctions(
                x_value=entry['x'],
                reference_y1=entry['y1'],
                reference_y2=entry['y2']
            ))
        except IntegrityError as e:
            print(f"Error inserting reference function entry: {e}")

    def store_evaluation_results(self, entry):
        """Save test evaluation results while computing deviation."""
        matched_function_id = self.identify_best_fit(entry['x'])
        ideal_y = self.retrieve_reference_y(matched_function_id, entry['x'])
        deviation = abs(entry['y'] - ideal_y)

        try:
            self.dbConn.add(EvaluationResults(
                x_value=entry['x'],
                test_y_value=entry['y'],
                delta_y_deviation=deviation,
                matched_function_id=matched_function_id
            ))
        except IntegrityError as e:
            print(f"Error inserting evaluation result: {e}")

    def identify_best_fit(self, x_value):
        """Determine the best matching reference function for a given x."""
        return 1  # Placeholder logic

    def retrieve_reference_y(self, function_id, x_value):
        """Fetch the corresponding y-value from the reference functions."""
        reference_entry = self.dbConn.query(ReferenceFunctions).filter_by(x_value=x_value).first()
        if reference_entry:
            return getattr(reference_entry, f'reference_y{function_id}')
        else:
            raise ValueError(f"No matching reference function found for x={x_value}")

    def plot_evaluation_results(self):
        """Graphically represent test deviations using matplotlib."""
        outputs = self.dbConn.query(EvaluationResults).all()
        x_values = [output.x_value for output in outputs]
        deviation_values_delta = [output.delta_y_deviation for output in outputs]

        plt.figure(figsize=(10, 6))
        plt.scatter(x_values, deviation_values_delta, label='Deviation (Delta Y)')
        plt.title('Test Evaluation: Deviation vs. X')
        plt.xlabel('X-Value')
        plt.ylabel('Deviation')
        plt.grid(True)
        plt.legend()
        plt.show()

if __name__ == "__main__":
    manager = DatasetHandler(dbConn)

    manager.load_dataset('/content/drive/MyDrive/Dataset/lokesh/train.csv', 'training')
    manager.load_dataset('/content/drive/MyDrive/Dataset/lokesh/ideal.csv', 'reference')

    manager.load_dataset('/content/drive/MyDrive/Dataset/lokesh/test.csv', 'evaluation')

    manager.plot_evaluation_results()

